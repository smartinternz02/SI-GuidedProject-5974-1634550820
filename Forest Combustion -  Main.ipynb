{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.2.4\n",
      "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
      "\u001b[K     |████████████████████████████████| 312 kB 22.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from keras==2.2.4) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from keras==2.2.4) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from keras==2.2.4) (1.19.2)\n",
      "Collecting keras-applications>=1.0.6\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 18.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from keras==2.2.4) (1.1.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from keras==2.2.4) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from keras==2.2.4) (5.4.1)\n",
      "Installing collected packages: keras-applications, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (2.4.4)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8 MB 25.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 13.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (3.11.2)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (2.4.1)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from protobuf>=3.9.2->tensorflow) (52.0.0.post20211006)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.1)\n",
      "Installing collected packages: grpcio, opt-einsum, flatbuffers\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.35.0\n",
      "    Uninstalling grpcio-1.35.0:\n",
      "      Successfully uninstalled grpcio-1.35.0\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.1.0\n",
      "    Uninstalling opt-einsum-3.1.0:\n",
      "      Successfully uninstalled opt-einsum-3.1.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 20210226132247\n",
      "    Uninstalling flatbuffers-20210226132247:\n",
      "      Successfully uninstalled flatbuffers-20210226132247\n",
      "Successfully installed flatbuffers-1.12 grpcio-1.32.0 opt-einsum-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import keras library\n",
    "import keras\n",
    "#import ImageDataGenerator class from keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the parameters /arguments for ImageDataGenerator class\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,\n",
    "                                 shear_range=0.2,\n",
    "                                 rotation_range=180,\n",
    "                                 zoom_range=0.2,\n",
    "                                 horizontal_flip=True)\n",
    "\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "\n",
    "if os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n",
    "    endpoint_8052a2d7c52f48e4ab60b18de89d62e6 = 'https://s3.us.cloud-object-storage.appdomain.cloud'\n",
    "else:\n",
    "    endpoint_8052a2d7c52f48e4ab60b18de89d62e6 = 'https://s3.private.us.cloud-object-storage.appdomain.cloud'\n",
    "\n",
    "client_8052a2d7c52f48e4ab60b18de89d62e6 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='zkg-BXeHKkTSbl9X1_t4wL7W0VcvwUqzqk0GZrfNGIw-',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=endpoint_8052a2d7c52f48e4ab60b18de89d62e6)\n",
    "\n",
    "streaming_body_2 = client_8052a2d7c52f48e4ab60b18de89d62e6.get_object(Bucket='fireforestcombustion-donotdelete-pr-8rofnwrxuzplkh', Key='Dataset.zip')['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip=zipfile.ZipFile(BytesIO(streaming_body_2 .read()),'r')\n",
    "file_paths=unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames=os.listdir('/home/wsuser/work/Dataset/train_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 436 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train = train_datagen.flow_from_directory('/home/wsuser/work/Dataset/train_set',\n",
    "                                            target_size = (128,128),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test = test_datagen.flow_from_directory('/home/wsuser/work/Dataset/test_set',\n",
    "                                          target_size = (128,128),\n",
    "                                          batch_size = 32,\n",
    "                                          class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'forest': 0, 'with fire': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import model building libraries'''\n",
    "\n",
    "#To define linear intialisation import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "#To add layers import Dense\n",
    "from tensorflow.keras.layers import Dense\n",
    "#To create Convolution kernel import Convolution2D\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "#import Maxpooling layer\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "#import Flatten layer\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intializing the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add convolutional layer\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add flatten layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add hidden layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='relu',units=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add hidden layermodel.add(Dense(output_dim=64,init='uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add output layer\n",
    "model.add(Dense(kernel_initializer='uniform',activation='sigmoid',units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the learning process\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 25s 2s/step - loss: 1.5271 - accuracy: 0.6147 - val_loss: 0.3571 - val_accuracy: 0.8264\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.3457 - accuracy: 0.8581 - val_loss: 0.1658 - val_accuracy: 0.9174\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2349 - accuracy: 0.9131 - val_loss: 0.0955 - val_accuracy: 0.9752\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 23s 2s/step - loss: 0.2124 - accuracy: 0.9076 - val_loss: 0.0816 - val_accuracy: 0.9669\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2018 - accuracy: 0.9190 - val_loss: 0.0717 - val_accuracy: 0.9835\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.1684 - accuracy: 0.9408 - val_loss: 0.0579 - val_accuracy: 0.9835\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.1964 - accuracy: 0.9188 - val_loss: 0.1010 - val_accuracy: 0.9504\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2120 - accuracy: 0.9065 - val_loss: 0.1540 - val_accuracy: 0.9256\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.2515 - accuracy: 0.8911 - val_loss: 0.0640 - val_accuracy: 0.9752\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 22s 2s/step - loss: 0.1408 - accuracy: 0.9558 - val_loss: 0.0489 - val_accuracy: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f50ec749070>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit_generator(x_train,steps_per_epoch=14,\n",
    "                    epochs=10,validation_data=x_test,\n",
    "                    validation_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save(\"fireforest.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fireforest.h5\r\n"
     ]
    }
   ],
   "source": [
    "!tar -zcvf image-classification-model_new.tgz fireforest.h5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mDataset\u001b[0m/\r\n",
      "fireforest.h5\r\n",
      "image-classification-model_new.tgz\r\n"
     ]
    }
   ],
   "source": [
    "ls -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watson-machine-learning-client\n",
      "  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n",
      "\u001b[K     |████████████████████████████████| 538 kB 30.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.2.4)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (4.59.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.17.46)\n",
      "Requirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2021.10.8)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (0.8.9)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.26.6)\n",
      "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (0.3.3)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (0.3.6)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.46 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (1.20.88)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from botocore<1.21.0,>=1.20.46->boto3->watson-machine-learning-client) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.46->boto3->watson-machine-learning-client) (1.15.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.7.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.7.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk-core==2.7.0->ibm-cos-sdk->watson-machine-learning-client) (0.15.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->watson-machine-learning-client) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->watson-machine-learning-client) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas->watson-machine-learning-client) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas->watson-machine-learning-client) (1.19.2)\n",
      "Installing collected packages: watson-machine-learning-client\n",
      "Successfully installed watson-machine-learning-client-1.0.391\n"
     ]
    }
   ],
   "source": [
    "!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "wml_credentials= {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\":\"1mFsOkZzzHVK0xr-SCoIRqms_vTh6kVjfJDBsI8wnsnU\"\n",
    "}\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_from_space_name(client,space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    return(next(item for item in space['resources'] if item['entity'][\"name\"] == space_name)['metadata']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space UID =3419d301-7f1c-4115-add6-161e6485ca78\n"
     ]
    }
   ],
   "source": [
    "space_uid = guid_from_space_name(client,'forestcombustion')\n",
    "print(\"Space UID =\" +space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------------------------------  ----\n",
      "NAME                           ASSET_ID                              TYPE\n",
      "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
      "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n",
      "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
      "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
      "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
      "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
      "tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\n",
      "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
      "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
      "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
      "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
      "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
      "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
      "tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\n",
      "do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\n",
      "autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n",
      "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
      "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
      "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
      "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n",
      "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
      "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
      "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
      "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
      "default_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\n",
      "autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n",
      "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
      "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
      "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
      "autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\n",
      "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
      "spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n",
      "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
      "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
      "cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n",
      "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
      "pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n",
      "spark-mllib_2.3-r_3.6          6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\n",
      "tensorflow_2.4-py3.7           65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\n",
      "spss-modeler_18.2              687eddc9-028a-4117-b9dd-e57b36f1efa5  base\n",
      "pytorch-onnx_1.2-py3.6         692a6a4d-2c4d-45ff-a1ed-b167ee55469a  base\n",
      "do_12.9                        75a3a4b0-6aa0-41b3-a618-48b1f56332a6  base\n",
      "spark-mllib_2.3-scala_2.11     7963efe5-bbec-417e-92cf-0574e21b4e8d  base\n",
      "spark-mllib_2.4-py37           7abc992b-b685-532b-a122-a396a3cdbaab  base\n",
      "caffe_1.0-py3.6                7bb3dbe2-da6e-4145-918d-b6d84aa93b6b  base\n",
      "pytorch-onnx_1.7-py3.7         812c6631-42b7-5613-982b-02098e6c909c  base\n",
      "cuda-py3.6                     82c79ece-4d12-40e6-8787-a7b9e0f62770  base\n",
      "tensorflow_1.15-py3.6-horovod  8964680e-d5e4-5bb8-919b-8342c6c0dfd8  base\n",
      "hybrid_0.1                     8c1a58c6-62b5-4dc4-987a-df751c2756b6  base\n",
      "pytorch-onnx_1.3-py3.7         8d5d8a87-a912-54cf-81ec-3914adaa988d  base\n",
      "-----------------------------  ------------------------------------  ----\n",
      "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n"
     ]
    }
   ],
   "source": [
    "client.software_specifications.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2b73a275-7cbf-420b-a912-eae7f436e0bc'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"tensorflow_1.15-py3.6\")\n",
    "software_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Warnings!! :  Model type keras_2.2.4 is deprecated. We recommend you use a supported model type. See Supported Frameworks https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html\n"
     ]
    }
   ],
   "source": [
    "model_details = client.repository.store_model(model='image-classification-model_new.tgz',meta_props={\n",
    "    client.repository.ModelMetaNames.NAME:\"CNN\",\n",
    "    client.repository.ModelMetaNames.TYPE:\"keras_2.2.4\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid}\n",
    "                                             )\n",
    "model_id=client.repository.get_model_uid(model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'448636fc-5dc9-4d31-a06f-06bca5b40008'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model content to file: 'forest.tar.gz'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work/forest.tar.gz'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.repository.download(model_id, 'forest.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"fireforest.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not StreamingBody",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/wsuser/ipykernel_154/3386502898.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# pandas documentation: http://pandas.pydata.org/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreaming_body_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m   \"\"\"\n\u001b[0;32m--> 299\u001b[0;31m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0m\u001b[1;32m    300\u001b[0m                         target_size=target_size, interpolation=interpolation)\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not StreamingBody"
     ]
    }
   ],
   "source": [
    "\n",
    "streaming_body_3 = client_8052a2d7c52f48e4ab60b18de89d62e6.get_object(Bucket='fireforestcombustion-donotdelete-pr-8rofnwrxuzplkh', Key='with fire (1).png')['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "img = image.load_img(streaming_body_3,target_size=(64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import load_model from keras.model\n",
    "from keras.models import load_model\n",
    "#import image class from keras\n",
    "from keras.preprocessing import image\n",
    "#import numpy\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model\n",
    "model = load_model(\"forest1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#give any random image path\n",
    "img = image.load_img(r'E:\\Guided Projects Github\\Detecting-Forest-Combustion-in-Forests-main\\Dataset\\train_set\\forest\\with_fire (1).gif',target_size = (128,128))\n",
    "x = image.img_to_array(img)\n",
    "#expand the image shape\n",
    "x = np.expand_dims(x,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_imgs, val_labels = x_test.__getitem__(0)\n",
    "\n",
    "preds = model.predict(val_imgs)\n",
    "fig, axes = plt.subp\n",
    "lots(4, 4, figsize=(16, 16))\n",
    "\n",
    "for img, label, pred, ax in zip(val_imgs, val_labels, preds, axes.flatten()):\n",
    "    ax.imshow(img)\n",
    "    ax.set_title('GT %d, Pred %.2f' % (label, pred))\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opencv prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#import facevec\n",
    "import numpy as np\n",
    "import smtplib\n",
    "from keras.preprocessing import image \n",
    "from keras.models  import load_model\n",
    "from twilio.rest import Client\n",
    "\n",
    "model = load_model(r'forest1.h5') \n",
    "video = cv2.VideoCapture(0)\n",
    "name = ['forest','with fire']\n",
    "    \n",
    "while(1):\n",
    "    success, frame = video.read()\n",
    "    cv2.imwrite(\"1.jpg\",frame)\n",
    "    img = image.load_img(\"1.jpg\",target_size = (128,128,3))\n",
    "    x  = image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis = 0)\n",
    "    pred = model.predict_classes(x)\n",
    "    p = pred[0][0]\n",
    "    print(pred)\n",
    "    cv2.putText(frame, np.array(x_train)[indices.astype(int)])\n",
    "    #out_images = np.array(X_train)[indices.astype(int)]\n",
    "    \n",
    "    pred = model.predict_classes(x)\n",
    "    if pred[0]==1:\n",
    "        account_sid = 'AC7cf10e025b98efe6b43870aec9660062'\n",
    "        auth_token = '6face7a62a524d2072ef605842feabb5'\n",
    "        client = Client(account_sid, auth_token)\n",
    "\n",
    "        message = client.messages \\\n",
    "        .create(\n",
    "         body='Forest Fire is detected, stay alert',\n",
    "         from_=' +12183220515', #twilio free number\n",
    "         to='+919302455750')\n",
    "        print(message.sid)\n",
    "    \n",
    "        print('Fire Detected')\n",
    "        print ('SMS sent!')\n",
    "        break\n",
    "    else:\n",
    "        print(\"no danger\")\n",
    "       #break\n",
    "    cv2.imshow(\"image\",frame)\n",
    "   \n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'): \n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
